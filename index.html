<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="None">
        
        
        <link rel="shortcut icon" href="img/favicon.ico">
        <title>Prof Docs</title>
        <link href="css/bootstrap.min.css" rel="stylesheet">
        <link href="css/fontawesome.min.css" rel="stylesheet">
        <link href="css/brands.min.css" rel="stylesheet">
        <link href="css/solid.min.css" rel="stylesheet">
        <link href="css/v4-font-face.min.css" rel="stylesheet">
        <link href="css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body class="homepage">
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href=".">Prof Docs</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a href="https://github.com/AlexsanderHamir/prof" class="nav-link"><i class="fa-brands fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#profiling-data-management" class="nav-link">Profiling Data Management</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#quick-reference" class="nav-link">Quick Reference</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#auto" class="nav-link">Auto</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#auto-configuration" class="nav-link">Auto - Configuration</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#tui-interactive-selection" class="nav-link">TUI - Interactive Selection</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#manual" class="nav-link">Manual</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#manual-configuration" class="nav-link">Manual - Configuration</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#performance-comparison" class="nav-link">Performance Comparison</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#track-auto" class="nav-link">Track Auto</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#track-manual" class="nav-link">Track Manual</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#tui-track-interactive-performance-comparison" class="nav-link">TUI Track - Interactive Performance Comparison</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#output-formats-supported" class="nav-link">Output formats supported:</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#cicd-fail-on-regressions" class="nav-link">CI/CD: Fail on regressions</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="profiling-data-management">Profiling Data Management</h1>
<p>When performing complex profiling, developers often find themselves lost in a maze of repetitive commands and scattered files. You run <code>go test -bench=BenchmarkMyFunc -cpuprofile=cpu.out</code>, then <code>go tool pprof -top cpu.out &gt; results.txt</code>, inspect a function with <code>go tool pprof -list=MyFunc cpu.out</code>, make modifications, run the benchmark again—and hours later, you're exhausted, have dozens of inconsistently named files scattered across directories, and can't remember which changes led to which results. Without systematic organization, you lose track of your optimization journey, lack accurate "before and after" snapshots to share with your team, and waste valuable time context-switching between profiling commands instead of focusing on actual performance improvements. Prof eliminates this chaos by capturing everything in one command and automatically organizing all profiling data—binary files, text reports, function-level analysis, and visualizations—into a structured, tagged hierarchy that preserves your optimization history and makes collaboration effortless.</p>
<h2 id="quick-reference">Quick Reference</h2>
<p><strong>Main Commands:</strong></p>
<ul>
<li><strong><code>prof auto</code></strong>: Automated benchmark collection and profiling</li>
<li><strong><code>prof tui</code></strong>: Interactive benchmark collection</li>
<li><strong><code>prof tui track</code></strong>: Interactive performance comparison</li>
<li><strong><code>prof manual</code></strong>: Process existing profile files</li>
<li><strong><code>prof track auto</code></strong>: Compare performance between tags</li>
<li><strong><code>prof track manual</code></strong>: Compare external profile files</li>
</ul>
<p><strong>Directory Flexibility:</strong></p>
<ul>
<li><strong>Project root</strong>: Run from anywhere in your Go project (recommended)</li>
<li><strong>Configuration</strong>: Configuration file (<code>config_template.json</code>) is always looked for at the project root</li>
<li><strong>Global Search</strong>: prof auto searches for the benchmark name globally, regardless of the directory you run it from. If you run it from a subdirectory, the <strong>bench</strong> directory will be created there instead of at the project root.</li>
</ul>
<h2 id="auto">Auto</h2>
<p>The <code>auto</code> command wraps <code>go test</code> and <code>pprof</code> to run benchmarks, collect all profile types, and organize everything automatically:</p>
<pre><code class="language-bash">prof auto --benchmarks &quot;BenchmarkGenPool&quot; --profiles &quot;cpu,memory,mutex,block&quot; --count 10 --tag &quot;baseline&quot;
</code></pre>
<p>This single command replaces dozens of manual steps and creates a complete, organized profiling dataset ready for analysis or comparison.</p>
<p><strong>Output Structure:</strong></p>
<pre><code>bench/baseline/
├── description.txt                 # User documentation for this run
├── bin/BenchmarkGenPool/           # Binary profile files
│   ├── BenchmarkGenPool_cpu.out
│   ├── BenchmarkGenPool_memory.out
│   ├── BenchmarkGenPool_mutex.out
│   └── BenchmarkGenPool_block.out
├── text/BenchmarkGenPool/          # Text reports &amp; benchmark output
│   ├── BenchmarkGenPool_cpu.txt
│   ├── BenchmarkGenPool_memory.txt
│   └── BenchmarkGenPool.txt
├── cpu_functions/BenchmarkGenPool/ # Function-level CPU profile data
│   ├── Put.txt
│   ├── Get.txt
│   └── getShard.txt
└── memory_functions/BenchmarkGenPool/ # Function-level memory profile data
    ├── Put.txt
    └── allocator.txt
</code></pre>
<h2 id="auto-configuration">Auto - Configuration</h2>
<p>By default, prof gathers code-level data for every function listed in a profile’s text report. To change this behavior, run:</p>
<pre><code class="language-bash">prof setup
</code></pre>
<p>This creates a configuration file with the following structure:</p>
<pre><code class="language-json">{
  &quot;function_collection_filter&quot;: {
    &quot;BenchmarkGenPool&quot;: {
      &quot;include_prefixes&quot;: [&quot;github.com/example/GenPool&quot;],
      &quot;ignore_functions&quot;: [&quot;init&quot;, &quot;TestMain&quot;, &quot;BenchmarkMain&quot;]
    }
  }
}
</code></pre>
<p><strong>Configuration Options:</strong></p>
<ul>
<li><code>BenchmarkGenPool</code>: Replace it with your benchmark function name, or with <code>"*"</code> to apply for all benchmarks.</li>
<li><code>include_prefixes</code>: Only collect functions whose names start with these prefixes.</li>
<li><code>ignore_functions</code>: Exclude specific functions from collection, even if they match the include prefixes.</li>
</ul>
<h2 id="tui-interactive-selection">TUI - Interactive Selection</h2>
<p>The <code>tui</code> command provides an interactive terminal interface that automatically discovers benchmarks in your project and guides you through the selection process:</p>
<pre><code class="language-bash">prof tui
</code></pre>
<p><strong>What it does:</strong></p>
<ol>
<li><strong>Discovers benchmarks</strong>: Automatically scans your Go module for <code>func BenchmarkXxx(b *testing.B)</code> functions in <code>*_test.go</code> files.</li>
<li><strong>Interactive selection</strong>: Presents a menu where you can select:</li>
<li>Which benchmarks to run (multi-select from discovered list)</li>
<li>Which profiles to collect (cpu, memory, mutex, block)</li>
<li>Number of benchmark runs (count)</li>
<li>Tag name for organizing results</li>
</ol>
<p><strong>Navigation:</strong></p>
<ul>
<li><strong>Page size</strong>: Shows up to 20 benchmarks at once for readability</li>
<li><strong>Scroll</strong>: Use arrow keys (↑/↓) to navigate through the list</li>
<li><strong>Multi-select</strong>: Use spacebar to select/deselect benchmarks</li>
<li><strong>Search</strong>: Type to filter and find specific benchmarks quickly</li>
</ul>
<h2 id="manual">Manual</h2>
<p>The <code>manual</code> command processes existing profile files without running benchmarks - it only uses <code>pprof</code> to organize data you already have:</p>
<pre><code class="language-bash">prof manual --tag &quot;external-profiles&quot; BenchmarkGenPool_cpu.out memory.out block.out
</code></pre>
<p>This organizes your existing profile files into a flatter structure based on the profile filename:</p>
<p><strong>Manual Output Structure:</strong></p>
<pre><code>bench/external-profiles/
├── BenchmarkGenPool_cpu/
│   ├── BenchmarkGenPool_cpu.txt    # Text report
│   └── functions/                  # Function-level profile data
│       ├── Put.txt
│       ├── Get.txt
│       └── getShard.txt
├── memory/
│   ├── memory.txt                  # Text report
│   └── functions/                  # Function-level profile data
│       └── allocator.txt
└── block/
    ├── block.txt                   # Text report
    └── functions/                  # Function-level profile data
        └── runtime.txt
</code></pre>
<h2 id="manual-configuration">Manual - Configuration</h2>
<p>The configuration works the same as auto configuration, except you should use profile file base names (without extensions) instead of benchmark names:</p>
<pre><code class="language-json">{
  &quot;function_collection_filter&quot;: {
    &quot;BenchmarkGenPool_cpu&quot;: {
      &quot;include_prefixes&quot;: [&quot;github.com/example/GenPool&quot;],
      &quot;ignore_functions&quot;: [&quot;init&quot;, &quot;TestMain&quot;, &quot;BenchmarkMain&quot;]
    }
  }
}
</code></pre>
<p>For example, <code>BenchmarkGenPool_cpu.out</code> becomes <code>BenchmarkGenPool_cpu</code> in the configuration.</p>
<p>Use <code>*</code> if you want the config to be applied to all profile files.</p>
<h1 id="performance-comparison">Performance Comparison</h1>
<p>Prof's performance comparison automatically drills down from benchmark-level changes to show you exactly which functions changed. Instead of just reporting that performance improved or regressed, Prof pinpoints the specific functions responsible and shows you detailed before-and-after comparisons.</p>
<h2 id="track-auto">Track Auto</h2>
<p>Use <code>track auto</code> when comparing data collected with <code>prof auto</code>. Simply reference the tag names:</p>
<pre><code class="language-bash">prof track auto --base &quot;baseline&quot; --current &quot;optimized&quot; \
                --profile-type &quot;cpu&quot; --bench-name &quot;BenchmarkGenPool&quot; \
                --output-format &quot;summary&quot;

prof track auto --base &quot;baseline&quot; --current &quot;optimized&quot; \
                --profile-type &quot;cpu&quot; --bench-name &quot;BenchmarkGenPool&quot; \
                --output-format &quot;detailed&quot;
</code></pre>
<h2 id="track-manual">Track Manual</h2>
<p>Use <code>track manual</code> when comparing external profile files by specifying their relative paths:</p>
<pre><code class="language-bash">prof track manual --base path/to/base/report/cpu.txt \
                  --current path/to/current/report/cpu.txt \
                  --output-format &quot;summary&quot;

prof track manual --base path/to/base/report/cpu.txt \
                  --current path/to/current/report/cpu.txt \
                  --output-format &quot;detailed&quot;
</code></pre>
<h2 id="tui-track-interactive-performance-comparison">TUI Track - Interactive Performance Comparison</h2>
<p>The <code>tui track</code> command provides an interactive interface for comparing performance between existing benchmark runs. This is a companion to the main <code>prof tui</code> command and requires that you have already collected benchmark data using either <code>prof tui</code> or <code>prof auto</code>.</p>
<pre><code class="language-bash">prof tui track
</code></pre>
<p><strong>What it does:</strong></p>
<ol>
<li><strong>Discovers existing data</strong>: Scans the <code>bench/</code> directory for tags you've already collected</li>
<li><strong>Interactive selection</strong>: Guides you through selecting:</li>
<li>Baseline tag (the "before" version)</li>
<li>Current tag (the "after" version)</li>
<li>Benchmark to compare</li>
<li>Profile type to analyze</li>
<li>Output format</li>
<li>Regression threshold settings</li>
</ol>
<p><strong>Prerequisites:</strong></p>
<ul>
<li>Must have run <code>prof tui</code> or <code>prof auto</code> at least twice to create baseline and current tags</li>
<li>Data must be organized under <code>bench/&lt;tag&gt;/</code> directories</li>
</ul>
<h2 id="output-formats-supported">Output formats supported:</h2>
<p>Prof's performance comparison provides multiple output formats to help you understand performance changes at different levels of detail and presentation.</p>
<ul>
<li><strong>summary</strong>: High-level overview of all performance changes</li>
<li><strong>detailed</strong>: Comprehensive analysis for each changed function</li>
<li><strong>summary-html</strong>: HTML export of summary report</li>
<li><strong>detailed-html</strong>: HTML export of detailed report</li>
<li><strong>summary-json</strong>: JSON export of summary report</li>
<li><strong>detailed-json</strong>: JSON export of detailed report</li>
</ul>
<h3 id="summary-format">Summary Format</h3>
<p>The summary format gives you a high-level overview of all performance changes, organized by impact:</p>
<pre><code>==== Performance Tracking Summary ====
Total Functions Analyzed: 78
Regressions: 9
Improvements: 8
Stable: 61

⚠️  Top Regressions (worst first):
• internal/cache.getShard: +200.0% (0.030s → 0.090s)
• internal/hash.Spread: +180.0% (0.050s → 0.140s)
• pool/acquire: +150.0% (0.020s → 0.050s)
• encoding/json.Marshal: +125.0% (0.080s → 0.180s)
• sync.Pool.Get: +100.0% (0.010s → 0.020s)

✅ Top Improvements (best first):
• compress/gzip.NewWriter: -100.0% (0.020s → 0.000s)
• internal/metrics.resetCounters: -100.0% (0.010s → 0.000s)
• encoding/json.Unmarshal: -95.0% (0.100s → 0.005s)
• net/url.ParseQuery: -90.0% (0.050s → 0.005s)
• pool/isFull: -85.0% (0.020s → 0.003s)
</code></pre>
<h3 id="detailed-format">Detailed Format</h3>
<p>The detailed format provides comprehensive analysis for each changed function, including impact assessment and action recommendations:</p>
<pre><code>📊 Summary: 78 total functions | 🔴 9 regressions | 🟢 8 improvements | ⚪ 61 stable
📋 Report Order: Regressions first (worst → best), then Improvements (best → worst), then Stable

║ ║ ║ ║ ║ ║ ║      PERFORMANCE CHANGE REPORT

Function: github.com/Random/Pool/pool.getShard
Analysis Time: 2025-07-23 15:51:59 PDT
Change Type: REGRESSION
⚠️ Performance regression detected

║ ║ ║ ║ ║      FLAT TIME ANALYSIS

Before:        0.030000s
After:         0.090000s
Delta:         +0.060000s
Change:        +200.00%
Impact:        Function is 200.00% SLOWER

║ ║ ║ ║ ║      CUMULATIVE TIME ANALYSIS

Before:        0.030s
After:         0.100s
Delta:         +0.070s
Change:        +233.33%

║ ║ ║ ║ ║      IMPACT ASSESSMENT

Severity:      CRITICAL
Recommendation: Critical regression! Immediate investigation required.
</code></pre>
<h1 id="cicd-fail-on-regressions">CI/CD: Fail on regressions</h1>
<p><strong>Understanding the regression threshold:</strong></p>
<p>The <code>--regression-threshold</code> flag sets a percentage limit on performance regressions. When enabled with <code>--fail-on-regression</code>, the command will exit with a non-zero status code if any function's <strong>flat time</strong> regression exceeds this threshold.</p>
<p><strong>Flat time regression calculation:</strong></p>
<pre><code>Flat regression % = (current_time - baseline_time) / baseline_time × 100
</code></pre>
<p><strong>Example:</strong> If a function took 100ms in baseline and 110ms in current run:</p>
<ul>
<li>Flat regression = (110 - 100) / 100 × 100 = +10%</li>
<li>With <code>--regression-threshold 5.0</code>, this would fail the build</li>
<li>With <code>--regression-threshold 15.0</code>, this would pass</li>
</ul>
<p><strong>Note:</strong> The threshold applies to <strong>flat time</strong> (time spent directly in the function), not cumulative time (time including all called functions). Flat time gives a more direct measure of the function's own performance impact.</p>
<p><strong>Important:</strong> Prof commands can be run from the Go project root directory or from within specific package directories. The configuration file (if using one) is always expected at the project root, regardless of where you run the command from, any extra configuration files will be ignored.</p>
<pre><code class="language-bash">prof track auto \
  --base baseline \
  --current PR \
  --profile-type cpu \
  --bench-name BenchmarkGenPool \
  --output-format summary \
  --fail-on-regression \
  --regression-threshold 5.0
</code></pre>
<p><strong>Example GitHub Actions job:</strong></p>
<pre><code class="language-yaml">name: perf-regression-check
on: [pull_request]
jobs:
  check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-go@v5
        with:
          go-version: &quot;&gt;=1.24&quot;
      - name: Install prof
        run: go install github.com/AlexsanderHamir/prof/cmd/prof@latest
      - name: Collect baseline (main)
        run: |
          git fetch origin main --depth=1
          git checkout -qf origin/main
          # prof can be run from the Go project root directory
          cd ${{ github.workspace }}
          prof auto --benchmarks &quot;BenchmarkGenPool&quot; --profiles &quot;cpu&quot; --count 5 --tag baseline
      - name: Collect current (PR)
        run: |
          git checkout -
          # prof can be run from the Go project root directory
          cd ${{ github.workspace }}
          prof auto --benchmarks &quot;BenchmarkGenPool&quot; --profiles &quot;cpu&quot; --count 5 --tag PR
      - name: Compare and fail on regression
        run: |
          # prof can be run from the Go project root directory
          cd ${{ github.workspace }}
          prof track auto --base baseline --current PR \
            --profile-type cpu --bench-name &quot;BenchmarkGenPool&quot; \
            --output-format summary --fail-on-regression --regression-threshold 5.0
</code></pre></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = ".",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="js/base.js"></script>
        <script src="search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>

<!--
MkDocs version : 1.6.1
Build Date UTC : 2025-08-19 15:38:10.398314+00:00
-->
